#!/usr/bin/env python
# -*- coding: utf-8 -*-
import csv
import copy
import argparse
from collections import Counter, deque
# import google.generativeai as genai
from PIL import Image
import os
import cv2 as cv
import numpy as np
import subprocess
import sys

# Install mediapipe if not available
subprocess.check_call([sys.executable, "-m", "pip", "install", "mediapipe==0.10.0"])

import mediapipe as mp
from mediapipe.tasks.python import vision

# Add custom module path
sys.path.append('/content/my_modules')  # Replace with the actual path
from utils import CvFpsCalc
from model import KeyPointClassifier, PointHistoryClassifier

# Configure Generative AI API Key
genai.configure(api_key="AIzaSyAFGaB_HCq2ResIOTCsQFRQN1NpQEDx6F4")


def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--device", type=int, default=0)
    parser.add_argument("--width", help='cap width', type=int, default=1080)
    parser.add_argument("--height", help='cap height', type=int, default=720)

    parser.add_argument('--use_static_image_mode', action='store_true')
    parser.add_argument("--min_detection_confidence", type=float, default=0.7)
    parser.add_argument("--min_tracking_confidence", type=float, default=0.5)

    return parser.parse_args()


def gemini_implement(image_path):
    """
    Integrate with Gemini Generative AI.
    Input: Path to an image file.
    Output: Response text from the model.
    """
    model = genai.GenerativeModel(model_name="gemini-1.5-flash")
    with open(image_path, "rb") as img_file:
        response = model.generate_content(["What is in this photo?", img_file.read()])
    return response.text


def main():
    args = get_args()

    cap_device = args.device
    cap_width = args.width
    cap_height = args.height

    use_static_image_mode = args.use_static_image_mode
    min_detection_confidence = args.min_detection_confidence
    min_tracking_confidence = args.min_tracking_confidence

    # Camera Setup
    cap = cv.VideoCapture(cap_device)
    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)
    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)

    # Mediapipe Hands
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=use_static_image_mode,
        max_num_hands=1,
        min_detection_confidence=min_detection_confidence,
        min_tracking_confidence=min_tracking_confidence,
    )

    keypoint_classifier = KeyPointClassifier()
    point_history_classifier = PointHistoryClassifier()

    # Load Labels
    with open('model/keypoint_classifier/20_keypoint_classifier_label.csv', encoding='utf-8-sig') as f:
        keypoint_classifier_labels = [row[0] for row in csv.reader(f)]
    with open('model/point_history_classifier/point_history_classifier_label.csv', encoding='utf-8-sig') as f:
        point_history_classifier_labels = [row[0] for row in csv.reader(f)]

    # Initialize History and FPS Tracker
    cvFpsCalc = CvFpsCalc(buffer_len=10)
    history_length = 16
    point_history = deque(maxlen=history_length)
    finger_gesture_history = deque(maxlen=history_length)

    mode = 0

    while True:
        fps = cvFpsCalc.get()
        key = cv.waitKey(10)
        if key == 27:  # ESC
            break
        number, mode = select_mode(key, mode)

        ret, image = cap.read()
        if not ret:
            break

        image = cv.flip(image, 1)  # Mirror
        debug_image = copy.deepcopy(image)
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        if results.multi_hand_landmarks is not None:
            try:
                temp_file = "temp_frame.jpg"
                debug_image_pil = Image.fromarray(cv.cvtColor(debug_image, cv.COLOR_BGR2RGB))
                debug_image_pil.save(temp_file)
                response = gemini_implement(temp_file)
                print("Gemini AI Response:", response)
            finally:
                if os.path.exists(temp_file):
                    os.remove(temp_file)

            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                brect = calc_bounding_rect(debug_image, hand_landmarks)
                landmark_list = calc_landmark_list(debug_image, hand_landmarks)
                pre_processed_landmark_list = pre_process_landmark(landmark_list)
                pre_processed_point_history_list = pre_process_point_history(debug_image, point_history)

                logging_csv(number, mode, pre_processed_landmark_list, pre_processed_point_history_list)

                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)
                if hand_sign_id == 2:  # Pointing gesture
                    point_history.append(landmark_list[8])
                else:
                    point_history.append([0, 0])

                finger_gesture_id = 0
                if len(pre_processed_point_history_list) == (history_length * 2):
                    finger_gesture_id = point_history_classifier(pre_processed_point_history_list)

                finger_gesture_history.append(finger_gesture_id)
                most_common_fg_id = Counter(finger_gesture_history).most_common()

                debug_image = draw_bounding_rect(True, debug_image, brect)
                debug_image = draw_landmarks(debug_image, landmark_list)
                debug_image = draw_info_text(
                    debug_image,
                    brect,
                    handedness,
                    keypoint_classifier_labels[hand_sign_id],
                    point_history_classifier_labels[most_common_fg_id[0][0]],
                )
        else:
            point_history.append([0, 0])

        debug_image = draw_point_history(debug_image, point_history)
        debug_image = draw_info(debug_image, fps, mode, number)
        cv.imshow('Hand Gesture Recognition', debug_image)

    cap.release()
    cv.destroyAllWindows()


def select_mode(key, mode):
    number = -1
    if 48 <= key <= 57:  # Keys 0-9
        number = key - 48
    if key == 110:  # 'n'
        mode = 0
    if key == 107:  # 'k'
        mode = 1
    if key == 104:  # 'h'
        mode = 2
    return number, mode


# Supporting Functions (calc_bounding_rect, calc_landmark_list, etc.) remain unchanged
# Add them below this main code section

if __name__ == "__main__":
    main()